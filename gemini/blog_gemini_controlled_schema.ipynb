{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Controlled Generation with the Gemini API\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In the past, when we want Large Language Model to output specific format, such as JSON schema, we will need to perform supervise fine-tuning, which is time consuming where you need to prepare label dataset, setup training pipeline, secure accelerator compute resourses.\n",
        "\n",
        "\n",
        "Now with Gemini 1.5 Pro, it has changed the way we do things. By using controlled schema output configuration, Gemini can now output valid JSON schema that is loading by json library out of the box.\n",
        "\n",
        "Check this out!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --user --quiet google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"[your-project-id]\"\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "## Code Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09720c707f1c"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e45ea9a28734"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from vertexai import generative_models\n",
        "from vertexai.generative_models import GenerationConfig, GenerativeModel, Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74badac24b3e"
      },
      "source": [
        "### Gemini 1.5 Flash models\n",
        "\n",
        "You can set model output using `response_mime_type` configuration option in `generation_config`, and describe the format you want in response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4a9c4ebc507b"
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generation_config={\"response_mime_type\": \"application/json\"},\n",
        ")\n",
        "\n",
        "prompt = \"\"\"\n",
        "Based on the context below, identify the intent in two words and result the result as JSON schema:\n",
        "\n",
        "# Context\n",
        "Customer: \"Hello, I need to file a claim for the accident I was involved in last week. My car was severely damaged, and I have already reported the incident to the police. Can you guide me on the next steps to process my insurance claim?\"\n",
        "\n",
        "Agent: \"I'm sorry to hear about the accident. To assist you with your claim, I'll need some information. Could you please provide your policy number and a brief description of the incident?\"\n",
        "\n",
        "Customer: \"Sure, my policy number is 12345678. The incident occurred on the 5th of June. I was driving through an intersection when another car ran a red light and hit my vehicle from the side. Fortunately, no one was injured.\"\n",
        "\n",
        "# Return Schema\n",
        "Intent = {\"intent_name\": STRING}\n",
        "Return: list[Intent]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09e3f92c710c"
      },
      "source": [
        "Parse the response string to JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fee244ad523e",
        "outputId": "bb68604b-7118-4a55-ae18-324a462e8d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'intent_name': 'File Claim'}]\n"
          ]
        }
      ],
      "source": [
        "response = model.generate_content(prompt)\n",
        "\n",
        "json_response = json.loads(response.text)\n",
        "print(json_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52aeea15a479"
      },
      "source": [
        "### Gemini 1.5 Pro models\n",
        "\n",
        "With Gemini 1.5 Pro models, you can set `response_schema` parameter in `generation_config`, and the model output will strictly follow that schema.\n",
        "\n",
        "Note that when `response_schema` is specified, the `response_mime_type` has to be set to `application/json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "81cbb6bd51d8"
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\"gemini-1.5-pro\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "766346c046f9"
      },
      "source": [
        "Following the previous example, define the data structure for the model output. Note that all of the fields in the JSON are optional by default unless specified in the `required` field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "af3fa1fbff4f"
      },
      "outputs": [],
      "source": [
        "response_schema = {\n",
        "    \"type\": \"OBJECT\",\n",
        "    \"properties\": {\n",
        "        \"intent_name\": {\n",
        "            \"type\": \"STRING\",\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"intent_name\"],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82033e70bf6e"
      },
      "source": [
        "When prompting the model to generate the content, pass the schema to the `response_schema` field of the `generation_config`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5db8b91d5be0",
        "outputId": "cc5f0d9e-8876-4c20-d017-91bee62f14c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"intent_name\":\"file claim\"\n",
            "} \n"
          ]
        }
      ],
      "source": [
        "prompt2 = \"\"\"\n",
        "Based on the context below, identify the intent in two words sentence and result the result as JSON schema:\n",
        "\n",
        "# Context\n",
        "Customer: \"Hello, I need to file a claim for the accident I was involved in last week. My car was severely damaged, and I have already reported the incident to the police. Can you guide me on the next steps to process my insurance claim?\"\n",
        "\n",
        "Agent: \"I'm sorry to hear about the accident. To assist you with your claim, I'll need some information. Could you please provide your policy number and a brief description of the incident?\"\n",
        "\n",
        "Customer: \"Sure, my policy number is 12345678. The incident occurred on the 5th of June. I was driving through an intersection when another car ran a red light and hit my vehicle from the side. Fortunately, no one was injured.\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "response = model.generate_content(\n",
        "    prompt2,\n",
        "    generation_config=GenerationConfig(\n",
        "        response_mime_type=\"application/json\", response_schema=response_schema\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca9af4346be7"
      },
      "source": [
        "You can parse the response string to JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76b5284016c0",
        "outputId": "b1854310-fb42-4455-c372-401394497ee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'intent_name': 'file claim'}\n"
          ]
        }
      ],
      "source": [
        "json_response = json.loads(response.text)\n",
        "print(json_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
